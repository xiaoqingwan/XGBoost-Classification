{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Internet Use via XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **[Loaded the Data From a File](#download-the-data)**\n",
    "\n",
    "- **[Formatted the Data for XGBoost using One-Hot Encoding](#one-hot-encoding)**\n",
    "\n",
    "- **[Built an XGBoost Model for Classification](#build-tree)**\n",
    "\n",
    "- **[Optimize the XGBoost Parameters with Cross Validation and GridSearch()](#prune-tree)**\n",
    "\n",
    "- **[Built, Drew, Interpreted and Evaluated the Optimized XGBoost Model](#draw-tree)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # load and manipulate data and for One-Hot Encoding\n",
    "import numpy as np # calculate the mean and standard deviation\n",
    "import xgboost as xgb # XGBoost stuff\n",
    "from sklearn.model_selection import train_test_split # split  data into training and testing sets\n",
    "from sklearn.metrics import balanced_accuracy_score, roc_auc_score, make_scorer # for scoring during cross validation\n",
    "from sklearn.model_selection import GridSearchCV # cross validation\n",
    "from sklearn.metrics import confusion_matrix # creates a confusion matrix\n",
    "from sklearn.metrics import plot_confusion_matrix # draws a confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"download-the-data\"></a>\n",
    "# Import the data\n",
    "\n",
    "This dataset has been cleaned previously in R. \n",
    "\n",
    "These things were done:\n",
    "1. remove columns with more than 10% NA\n",
    "2. remove character columns\n",
    "3. remove id columns and the likes\n",
    "4. delete values like 9999 and 9998, which are \"Refused\" and \"Don't Know/ NA\"\n",
    "5. remove participants with missing outcome\n",
    "6. remove variables with near zero variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PA009</th>\n",
       "      <th>PA012</th>\n",
       "      <th>PA019</th>\n",
       "      <th>PA028</th>\n",
       "      <th>PA099</th>\n",
       "      <th>PA100</th>\n",
       "      <th>PA101</th>\n",
       "      <th>PA106</th>\n",
       "      <th>PA113</th>\n",
       "      <th>PVDATE</th>\n",
       "      <th>...</th>\n",
       "      <th>PJF478</th>\n",
       "      <th>PQR012</th>\n",
       "      <th>PQR010</th>\n",
       "      <th>PQR011</th>\n",
       "      <th>PJR478A</th>\n",
       "      <th>PF_CPL</th>\n",
       "      <th>PQ488_1A</th>\n",
       "      <th>PQ488_2A</th>\n",
       "      <th>PQ488_3A</th>\n",
       "      <th>COHORT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 315 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PA009  PA012  PA019  PA028  PA099  PA100  PA101  PA106  PA113  PVDATE  ...  \\\n",
       "0      1      1     76      5      0      0      0      0      0       3  ...   \n",
       "1      1      1     60      5      0      0      0      0      0       2  ...   \n",
       "2      1      1     70      5      0      2      2      2      4       3  ...   \n",
       "3      1      1     68      5      0      1      1      1      2       2  ...   \n",
       "4      1      1     79      5      0      2      2      2      4       2  ...   \n",
       "\n",
       "   PJF478  PQR012  PQR010  PQR011  PJR478A  PF_CPL  PQ488_1A  PQ488_2A  \\\n",
       "0     1.0     5.0     5.0     5.0      1.0       0       0.0       0.0   \n",
       "1     1.0     5.0     5.0     5.0      1.0       0       NaN       0.0   \n",
       "2     1.0     5.0     5.0     5.0      1.0       0       0.0       0.0   \n",
       "3     1.0     5.0     5.0     5.0      1.0       0       0.0       0.0   \n",
       "4     1.0     5.0     5.0     5.0      1.0       1       0.0       0.0   \n",
       "\n",
       "   PQ488_3A  COHORT  \n",
       "0       0.0       3  \n",
       "1       0.0       3  \n",
       "2       0.0       3  \n",
       "3       0.0       3  \n",
       "4       0.0       3  \n",
       "\n",
       "[5 rows x 315 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('h16f2a_cleaned_010221.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"format-the-data\"></a>\n",
    "# Split the Data into Dependent and Independent Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PA009</th>\n",
       "      <th>PA012</th>\n",
       "      <th>PA019</th>\n",
       "      <th>PA028</th>\n",
       "      <th>PA099</th>\n",
       "      <th>PA100</th>\n",
       "      <th>PA101</th>\n",
       "      <th>PA106</th>\n",
       "      <th>PA113</th>\n",
       "      <th>PVDATE</th>\n",
       "      <th>...</th>\n",
       "      <th>PJF478</th>\n",
       "      <th>PQR012</th>\n",
       "      <th>PQR010</th>\n",
       "      <th>PQR011</th>\n",
       "      <th>PJR478A</th>\n",
       "      <th>PF_CPL</th>\n",
       "      <th>PQ488_1A</th>\n",
       "      <th>PQ488_2A</th>\n",
       "      <th>PQ488_3A</th>\n",
       "      <th>COHORT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 314 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PA009  PA012  PA019  PA028  PA099  PA100  PA101  PA106  PA113  PVDATE  ...  \\\n",
       "0      1      1     76      5      0      0      0      0      0       3  ...   \n",
       "1      1      1     60      5      0      0      0      0      0       2  ...   \n",
       "2      1      1     70      5      0      2      2      2      4       3  ...   \n",
       "3      1      1     68      5      0      1      1      1      2       2  ...   \n",
       "4      1      1     79      5      0      2      2      2      4       2  ...   \n",
       "\n",
       "   PJF478  PQR012  PQR010  PQR011  PJR478A  PF_CPL  PQ488_1A  PQ488_2A  \\\n",
       "0     1.0     5.0     5.0     5.0      1.0       0       0.0       0.0   \n",
       "1     1.0     5.0     5.0     5.0      1.0       0       NaN       0.0   \n",
       "2     1.0     5.0     5.0     5.0      1.0       0       0.0       0.0   \n",
       "3     1.0     5.0     5.0     5.0      1.0       0       0.0       0.0   \n",
       "4     1.0     5.0     5.0     5.0      1.0       1       0.0       0.0   \n",
       "\n",
       "   PQ488_3A  COHORT  \n",
       "0       0.0       3  \n",
       "1       0.0       3  \n",
       "2       0.0       3  \n",
       "3       0.0       3  \n",
       "4       0.0       3  \n",
       "\n",
       "[5 rows x 314 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('PW303', axis=1).copy()\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: PW303, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['PW303'].replace({1:1, 5:0}, inplace=True)\n",
    "y = df['PW303'].copy()\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have created **X**, which has the data we want to use to make predictions, and **y**, which has the data we want to predict, we are ready to continue formatting **X** so that it is suitable for making a model with **XGBoost**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"one-hot-encoding\"></a>\n",
    "# Treat Categorical Predictors: One-Hot Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#note that this list has some columns that had zero variance that were removed already in X, so we need to find the intersection\n",
    "df1 = pd.read_csv('possible_categorical.csv')\n",
    "possible_categorical = df1['x'].tolist()\n",
    "#this is the list of categorical columns that will turn into dummies\n",
    "cat_col = list(set(possible_categorical).intersection(list(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PA019</th>\n",
       "      <th>PA100</th>\n",
       "      <th>PA101</th>\n",
       "      <th>PA106</th>\n",
       "      <th>PA113</th>\n",
       "      <th>PVDATE</th>\n",
       "      <th>PB132</th>\n",
       "      <th>PC139</th>\n",
       "      <th>PC229</th>\n",
       "      <th>PD182M1</th>\n",
       "      <th>...</th>\n",
       "      <th>PZ023_3.0</th>\n",
       "      <th>PZ023_4.0</th>\n",
       "      <th>PZ023_5.0</th>\n",
       "      <th>PZ023_6.0</th>\n",
       "      <th>PZ023_7.0</th>\n",
       "      <th>PN067_1.0</th>\n",
       "      <th>PN067_5.0</th>\n",
       "      <th>PC128_1.0</th>\n",
       "      <th>PC128_3.0</th>\n",
       "      <th>PC128_5.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 851 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PA019  PA100  PA101  PA106  PA113  PVDATE  PB132  PC139  PC229  PD182M1  \\\n",
       "0     76      0      0      0      0       3    8.0  140.0    0.0     17.0   \n",
       "1     60      0      0      0      0       2    0.0  190.0    3.0      1.0   \n",
       "2     70      2      2      2      4       3    9.0  150.0    0.0     19.0   \n",
       "3     68      1      1      1      2       2    6.0  131.0    0.0     16.0   \n",
       "4     79      2      2      2      4       2    8.0  160.0    0.0      4.0   \n",
       "\n",
       "   ...  PZ023_3.0  PZ023_4.0  PZ023_5.0  PZ023_6.0  PZ023_7.0  PN067_1.0  \\\n",
       "0  ...          1          0          0          0          0          0   \n",
       "1  ...          1          0          0          0          0          0   \n",
       "2  ...          1          0          0          0          0          1   \n",
       "3  ...          1          0          0          0          0          0   \n",
       "4  ...          1          0          0          0          0          0   \n",
       "\n",
       "   PN067_5.0  PC128_1.0  PC128_3.0  PC128_5.0  \n",
       "0          1          0          0          1  \n",
       "1          1          0          0          1  \n",
       "2          0          1          0          0  \n",
       "3          1          0          0          1  \n",
       "4          1          1          0          0  \n",
       "\n",
       "[5 rows x 851 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_encoded = pd.get_dummies(X, columns = cat_col)\n",
    "X_encoded.head() #now we have categorical columns turned into dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 20738 observations and 851 predictors (including dummies).\n"
     ]
    }
   ],
   "source": [
    "print ('We have ' + str(len(X_encoded)) + ' observations and ' + str(len(X_encoded.columns)) + ' predictors (including dummies).')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"build-tree\"></a>\n",
    "# Build A Preliminary XGBoost Model\n",
    "At long last, the data is correctly formatted for making an **XGBoost** model. Now we simply split the data into **training** and **testing** data sets and build the model. However, first, let's observe that this dataset is balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5692930851576815"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y)/len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that **56.9%** of the people in the dataset are internet users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train and test sets are also balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5719796823763904"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_train)/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5612343297974928"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** Instead of determining the optimal number of trees with cross validation, we will use **early stopping** to stop building trees when they no longer improve the situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-aucpr:0.85316\n",
      "[1]\tvalidation_0-aucpr:0.86764\n",
      "[2]\tvalidation_0-aucpr:0.87526\n",
      "[3]\tvalidation_0-aucpr:0.87967\n",
      "[4]\tvalidation_0-aucpr:0.88243\n",
      "[5]\tvalidation_0-aucpr:0.88642\n",
      "[6]\tvalidation_0-aucpr:0.88912\n",
      "[7]\tvalidation_0-aucpr:0.89061\n",
      "[8]\tvalidation_0-aucpr:0.89074\n",
      "[9]\tvalidation_0-aucpr:0.89194\n",
      "[10]\tvalidation_0-aucpr:0.89359\n",
      "[11]\tvalidation_0-aucpr:0.89358\n",
      "[12]\tvalidation_0-aucpr:0.89519\n",
      "[13]\tvalidation_0-aucpr:0.89556\n",
      "[14]\tvalidation_0-aucpr:0.89658\n",
      "[15]\tvalidation_0-aucpr:0.89638\n",
      "[16]\tvalidation_0-aucpr:0.89760\n",
      "[17]\tvalidation_0-aucpr:0.89787\n",
      "[18]\tvalidation_0-aucpr:0.89800\n",
      "[19]\tvalidation_0-aucpr:0.89834\n",
      "[20]\tvalidation_0-aucpr:0.89826\n",
      "[21]\tvalidation_0-aucpr:0.89872\n",
      "[22]\tvalidation_0-aucpr:0.89872\n",
      "[23]\tvalidation_0-aucpr:0.89817\n",
      "[24]\tvalidation_0-aucpr:0.89806\n",
      "[25]\tvalidation_0-aucpr:0.89730\n",
      "[26]\tvalidation_0-aucpr:0.89669\n",
      "[27]\tvalidation_0-aucpr:0.89702\n",
      "[28]\tvalidation_0-aucpr:0.89714\n",
      "[29]\tvalidation_0-aucpr:0.89668\n",
      "[30]\tvalidation_0-aucpr:0.89642\n",
      "[31]\tvalidation_0-aucpr:0.89637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=None, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=4, num_parallel_tree=1, random_state=42,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "clf_xgb = xgb.XGBClassifier(objective='binary:logistic', missing=None, seed=42)\n",
    "clf_xgb.fit(X_train, \n",
    "            y_train,\n",
    "            verbose=True,\n",
    "            ## the next three arguments set up early stopping.\n",
    "            early_stopping_rounds=10,\n",
    "            eval_metric='aucpr',\n",
    "            eval_set=[(X_test, y_test)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, we've built an **XGBoost** model for classification. Let's see how it performs on the **Testing Dataset** by running the **Testing Dataset** down the model and drawing a **Confusion Matrix**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fdb94d8dcd0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(clf_xgb, \n",
    "                      X_test, \n",
    "                      y_test,\n",
    "                      values_format='d',\n",
    "                      display_labels=[\"Non-user\", \"User\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The out-of-sample prediction accuracy is 0.7959498553519768\n"
     ]
    }
   ],
   "source": [
    "a = (1673+2454)/(1673+2454+602+456)\n",
    "print ('The out-of-sample prediction accuracy is ' + str(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a **XGBoost** model using only the default hyperparameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"optimize-parameters\"></a>\n",
    "# Optimize Parameters using Cross Validation and GridSearch()\n",
    "\n",
    "**XGBoost** has a lot of *hyperparameters*, parameters that we have to manually configure and are not determined by **XGBoost** itself, including `max_depth`, the maximum tree depth, `learning_rate`, the learning rate, or \"eta\", `gamma`, the parameter that encourages pruning, and `reg_lambda`, the regularization parameter lambda. So let's try to find the optimal values for these hyperparameters in hopes that we can improve the accuracy with the **Testing Dataset**.\n",
    "\n",
    "**NOTE:** Since we have many hyperparameters to optimize, we will use `GridSearchCV()`. We specify a bunch of potential values for the hyperparameters and `GridSearchCV()` tests all possible combinations of the parameters for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROUND 1\n",
    "# param_grid = {\n",
    "#     'max_depth': [3, 4, 5],\n",
    "#     'learning_rate': [0.1, 0.01, 0.05],\n",
    "#     'gamma': [0, 0.25, 1.0],\n",
    "#     'reg_lambda': [0, 1.0, 10.0],\n",
    "# }\n",
    "# Output: 'gamma': 1.0, 'learning_rate': 0.1, 'max_depth': 4, 'reg_lambda': 1.0}\n",
    "# 45 minutes\n",
    "# max depth and reg_lambda look good\n",
    "# Because learning_rate and gamma were at the ends of their range, we will continue to explore those...\n",
    "\n",
    "## ROUND 2\n",
    "# param_grid = {\n",
    "#     'max_depth': [4],\n",
    "#     'learning_rate': [0.1, 0.5, 1],\n",
    "#     'gamma': [1.0, 3.0, 5.0, 10.0],\n",
    "#     'reg_lambda': [1.0, 5.0],\n",
    "# }\n",
    "# Output: {'gamma': 5.0, 'learning_rate': 0.1, 'max_depth': 4, 'reg_lambda': 1.0}\n",
    "\n",
    "# NOTE: To speed up cross validiation, and to further prevent overfitting.\n",
    "# We are only using a random subset of the data (90%) and are only\n",
    "# using a random subset of the features (columns) (50%) per tree.\n",
    "# optimal_params = GridSearchCV(\n",
    "#     estimator=xgb.XGBClassifier(objective='binary:logistic', \n",
    "#                                 seed=42,\n",
    "#                                 subsample=0.9,\n",
    "#                                 colsample_bytree=0.5),\n",
    "#     param_grid=param_grid,\n",
    "#     scoring='roc_auc', ## see https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "#     verbose=0, # NOTE: If you want to see what Grid Search is doing, set verbose=2\n",
    "#     n_jobs = 10,\n",
    "#     cv = 3\n",
    "# )\n",
    "\n",
    "# optimal_params.fit(X_train, \n",
    "#                    y_train, \n",
    "#                    early_stopping_rounds=10,                \n",
    "#                    eval_metric='auc',\n",
    "#                    eval_set=[(X_test, y_test)],\n",
    "#                    verbose=False)\n",
    "# print(optimal_params.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, after testing all possible combinations of the potential parameter values with **Cross Validation**, we see that we should set `gamma=5.0`, `learn_rate=0.1`, `max_depth=4`, and `reg_lambda=1.0`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"draw-tree\"></a>\n",
    "# Building, Evaluating, Drawing, and Interpreting the Optimized XGBoost Model\n",
    "\n",
    "Now that we have the ideal parameter values, we can build the final **XGBoost** model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:04:07] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:541: \n",
      "Parameters: { learn_rate } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[0]\tvalidation_0-aucpr:0.81488\n",
      "[1]\tvalidation_0-aucpr:0.85122\n",
      "[2]\tvalidation_0-aucpr:0.86764\n",
      "[3]\tvalidation_0-aucpr:0.87465\n",
      "[4]\tvalidation_0-aucpr:0.87996\n",
      "[5]\tvalidation_0-aucpr:0.88253\n",
      "[6]\tvalidation_0-aucpr:0.88409\n",
      "[7]\tvalidation_0-aucpr:0.88609\n",
      "[8]\tvalidation_0-aucpr:0.88799\n",
      "[9]\tvalidation_0-aucpr:0.89050\n",
      "[10]\tvalidation_0-aucpr:0.89218\n",
      "[11]\tvalidation_0-aucpr:0.89409\n",
      "[12]\tvalidation_0-aucpr:0.89496\n",
      "[13]\tvalidation_0-aucpr:0.89728\n",
      "[14]\tvalidation_0-aucpr:0.89799\n",
      "[15]\tvalidation_0-aucpr:0.89806\n",
      "[16]\tvalidation_0-aucpr:0.89804\n",
      "[17]\tvalidation_0-aucpr:0.89840\n",
      "[18]\tvalidation_0-aucpr:0.89882\n",
      "[19]\tvalidation_0-aucpr:0.89932\n",
      "[20]\tvalidation_0-aucpr:0.89947\n",
      "[21]\tvalidation_0-aucpr:0.89989\n",
      "[22]\tvalidation_0-aucpr:0.90021\n",
      "[23]\tvalidation_0-aucpr:0.90088\n",
      "[24]\tvalidation_0-aucpr:0.90071\n",
      "[25]\tvalidation_0-aucpr:0.90166\n",
      "[26]\tvalidation_0-aucpr:0.90185\n",
      "[27]\tvalidation_0-aucpr:0.90233\n",
      "[28]\tvalidation_0-aucpr:0.90229\n",
      "[29]\tvalidation_0-aucpr:0.90252\n",
      "[30]\tvalidation_0-aucpr:0.90204\n",
      "[31]\tvalidation_0-aucpr:0.90237\n",
      "[32]\tvalidation_0-aucpr:0.90230\n",
      "[33]\tvalidation_0-aucpr:0.90230\n",
      "[34]\tvalidation_0-aucpr:0.90207\n",
      "[35]\tvalidation_0-aucpr:0.90218\n",
      "[36]\tvalidation_0-aucpr:0.90245\n",
      "[37]\tvalidation_0-aucpr:0.90238\n",
      "[38]\tvalidation_0-aucpr:0.90223\n",
      "[39]\tvalidation_0-aucpr:0.90204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.5, gamma=5.0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learn_rate=0.1, learning_rate=0.300000012, max_delta_step=0,\n",
       "              max_depth=4, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=4,\n",
       "              num_parallel_tree=1, random_state=42, reg_alpha=0, reg_lambda=1.0,\n",
       "              scale_pos_weight=1, seed=42, subsample=0.9, tree_method='exact',\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_xgb = xgb.XGBClassifier(seed=42,\n",
    "                        objective='binary:logistic',\n",
    "                        gamma=5.0,\n",
    "                        learn_rate=0.1,\n",
    "                        max_depth=4,\n",
    "                        reg_lambda=1.0,\n",
    "                        subsample=0.9,\n",
    "                        colsample_bytree=0.5)\n",
    "clf_xgb.fit(X_train, \n",
    "            y_train, \n",
    "            verbose=True, \n",
    "            early_stopping_rounds=10,\n",
    "            eval_metric='aucpr',\n",
    "            eval_set=[(X_test, y_test)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's draw another confusion matrix to see if the optimized **XGBoost** model does better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fd587554310>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(clf_xgb, \n",
    "                      X_test, \n",
    "                      y_test,\n",
    "                      values_format='d',\n",
    "                      display_labels=[\"Non-user\", \"User\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The out-of-sample prediction accuracy is 0.8\n"
     ]
    }
   ],
   "source": [
    "b = (1672+2476)/(1672+2476+603+434)\n",
    "print ('The out-of-sample prediction accuracy is ' + str(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PD240_1.0': 558.32946576,\n",
       " 'PQR011_5.0': 412.56048599999997,\n",
       " 'PG040_5.0': 264.295520675,\n",
       " 'PP005': 207.9834083833333,\n",
       " 'PD186': 190.9516550666667,\n",
       " 'PNSSCORE': 157.67088203461537,\n",
       " 'PN164_5.0': 151.9371148,\n",
       " 'PQ162_5.0': 132.981506,\n",
       " 'PQ344_1.0': 115.31477866666667,\n",
       " 'PQ162_1.0': 111.774643,\n",
       " 'PQ370_1.0': 97.3352966,\n",
       " 'PD184': 95.7676359325,\n",
       " 'PP155': 95.10874337999999,\n",
       " 'PN164_1.0': 80.5428619,\n",
       " 'PP097_3.0': 74.6907282,\n",
       " 'PN098_2': 74.07551559999999,\n",
       " 'PG198_5.0': 71.15340975000001,\n",
       " 'PNSSCORESE': 69.2861538,\n",
       " 'PQ344_5.0': 66.24606332500001,\n",
       " 'PD176': 65.66795406499999,\n",
       " 'PA012_1': 56.2859383,\n",
       " 'P025_1.0': 54.3916206,\n",
       " 'PA019': 51.12395854999998,\n",
       " 'PG086_5.0': 51.0143566,\n",
       " 'PD240_5.0': 47.4589233,\n",
       " 'PN023': 45.62172795,\n",
       " 'PN067_5.0': 42.8066559,\n",
       " 'PC128_5.0': 39.741863275,\n",
       " 'PQ375_1.0': 39.1147041,\n",
       " 'PC128_1.0': 38.217050775000004,\n",
       " 'PTN05_5': 37.4606031,\n",
       " 'PQ453_5.0': 36.03468705,\n",
       " 'PX060_R_2': 35.15820791666666,\n",
       " 'PQR010_1.0': 33.8315849,\n",
       " 'PN098_1': 32.3994141,\n",
       " 'PQ426': 30.874217617777774,\n",
       " 'PB132': 30.19057766,\n",
       " 'PC225_4.0': 29.9043331,\n",
       " 'PG013': 29.75869179,\n",
       " 'PN208': 29.62083435,\n",
       " 'PD174': 28.302084154,\n",
       " 'PC095_4': 27.7520663,\n",
       " 'PC134_6.0': 26.3341904,\n",
       " 'PQ477_5.0': 26.327254677999996,\n",
       " 'PQR010_5.0': 25.4417381,\n",
       " 'PP097_2.0': 25.3239632,\n",
       " 'PX067_R': 23.840226295000004,\n",
       " 'PH150_1.0': 22.993972749999998,\n",
       " 'PQR012_5.0': 21.6742249,\n",
       " 'PG047_5.0': 21.29229831666667,\n",
       " 'PN295_1.0': 19.80859088,\n",
       " 'PC271_1.0': 19.66773415,\n",
       " 'PC273_5.0': 19.5047493,\n",
       " 'PC096_2.0': 19.159652066666666,\n",
       " 'PD111_1.0': 19.149518343333334,\n",
       " 'PD101_4.0': 18.8168049,\n",
       " 'PN147': 18.80913587,\n",
       " 'PH002_1.0': 18.8088837,\n",
       " 'PTN05_1': 18.3094069,\n",
       " 'PC291_5.0': 17.8876839,\n",
       " 'PQ316_1.0': 17.4208145,\n",
       " 'PC287_5.0': 16.738022816666668,\n",
       " 'PC096_1.0': 16.7209665875,\n",
       " 'PH100_1.0': 16.695133833333333,\n",
       " 'PX060_R_1': 16.540158898333335,\n",
       " 'PP185_1.0': 16.29850896,\n",
       " 'PQ483_1_1.0': 16.12882805,\n",
       " 'PH151_1.0': 16.0110207,\n",
       " 'PH002_4.0': 15.966285699999998,\n",
       " 'PE046': 15.682852433333332,\n",
       " 'PC097_2.0': 15.6111374,\n",
       " 'PH100_5.0': 15.600256,\n",
       " 'PC065_5.0': 15.212562550000001,\n",
       " 'PY008': 15.051303116000003,\n",
       " 'PH001_5.0': 14.697355103333335,\n",
       " 'PN291_5.0': 14.639236,\n",
       " 'PC097_1.0': 14.56283903,\n",
       " 'PP183': 14.238989683333335,\n",
       " 'PD170': 14.172225633333332,\n",
       " 'PQ370_5.0': 14.033011123333333,\n",
       " 'PQ417': 13.728789197142858,\n",
       " 'PC183_1': 13.6944122,\n",
       " 'PVDATE': 13.579819366666667,\n",
       " 'PQ464_5.0': 13.3132563,\n",
       " 'PA101': 13.3084507,\n",
       " 'PC291_1.0': 13.257452,\n",
       " 'PA098': 13.22169785,\n",
       " 'PLBRTYPE_2': 13.0741062,\n",
       " 'PY095': 13.0467901,\n",
       " 'PY096': 13.000542705714285,\n",
       " 'PX026M': 12.992310394285711,\n",
       " 'PN175_7.0': 12.936664903333332,\n",
       " 'PQ477_1.0': 12.863194,\n",
       " 'PC224_1.0': 12.8166904,\n",
       " 'PN211': 12.74944545,\n",
       " 'PT047_1': 12.5652313,\n",
       " 'PN256': 12.54099561,\n",
       " 'PX065_R_1.0': 12.5130987,\n",
       " 'PG086_1.0': 12.263646105,\n",
       " 'PC097_4.0': 12.2223072,\n",
       " 'PC110_1.0': 11.985991975000001,\n",
       " 'PD191_2.0': 11.9653587,\n",
       " 'PN202_5.0': 11.8036118,\n",
       " 'PP175': 11.78907347,\n",
       " 'PQ182_5.0': 11.7172518,\n",
       " 'PD108M1_1.0': 11.5700378,\n",
       " 'PY113': 11.466649607142857,\n",
       " 'PN001_5.0': 11.4486351,\n",
       " 'PT036_1.0': 11.4300871,\n",
       " 'PD182M1': 11.409810552,\n",
       " 'PY111': 11.341826066,\n",
       " 'PC096_4.0': 11.280207636666667,\n",
       " 'PC109_1.0': 11.2372904,\n",
       " 'PN202_1.0': 11.217330480000001,\n",
       " 'PN236_1': 10.9699697,\n",
       " 'PD142': 10.942440906,\n",
       " 'PD102_2.0': 10.910667425,\n",
       " 'PQ119_1.0': 10.8748627,\n",
       " 'PC139': 10.769560611428572,\n",
       " 'PN332_1.0': 10.625797275,\n",
       " 'PQ133_5.0': 10.5406275,\n",
       " 'PC095_2': 10.4719963,\n",
       " 'PJ677_6': 10.4608631,\n",
       " 'PZ270_4.0': 10.4601679,\n",
       " 'PE105_1.0': 10.36008026,\n",
       " 'PN134_1.0': 10.303026205,\n",
       " 'PN207': 10.25642874,\n",
       " 'PY107': 10.2279726275,\n",
       " 'PC147_1.0': 10.1379948,\n",
       " 'PZ041_3.0': 10.1311646,\n",
       " 'PD185': 10.1043539,\n",
       " 'PT001_1.0': 10.061644555,\n",
       " 'PZ043_1.0': 10.0182257,\n",
       " 'PE140_0.0': 10.0073376,\n",
       " 'PY006': 10.005878835999999,\n",
       " 'PD189_1.0': 9.99229622,\n",
       " 'PG101_1': 9.97668076,\n",
       " 'PZ009_R': 9.93975137,\n",
       " 'PE111_5.0': 9.90983129,\n",
       " 'PP097_1.0': 9.854420675,\n",
       " 'PN295_3.0': 9.824135545,\n",
       " 'PY102': 9.805142866666667,\n",
       " 'PZ066_R_3.0': 9.77990627,\n",
       " 'PZ267_2.0': 9.72399426,\n",
       " 'PG010_5.0': 9.70931244,\n",
       " 'PC289_3.0': 9.64414692,\n",
       " 'PC001_4.0': 9.58042908,\n",
       " 'PD182M3': 9.521878236666668,\n",
       " 'PC102_1.0': 9.421463975,\n",
       " 'PG008_6.0': 9.40905952,\n",
       " 'PC001_2.0': 9.373359205,\n",
       " 'PZ010_R': 9.33687401,\n",
       " 'PC086_3.0': 9.32793236,\n",
       " 'PQR011_1.0': 9.3179884,\n",
       " 'PN134_5.0': 9.30507374,\n",
       " 'PY100': 9.285162731428573,\n",
       " 'PC223_4.0': 9.25795078,\n",
       " 'PA113': 9.20084445,\n",
       " 'PQ421_1.0': 9.150684046666667,\n",
       " 'PC223_2.0': 9.10509872,\n",
       " 'PQ446_5.0': 9.102453386666667,\n",
       " 'P085': 9.086300135,\n",
       " 'PG059_5.0': 9.07892799,\n",
       " 'PZ246': 8.980176606666667,\n",
       " 'PY106': 8.926372712,\n",
       " 'PJ689_4': 8.9067297,\n",
       " 'PY115': 8.8631460675,\n",
       " 'PC288_1.0': 8.84076881,\n",
       " 'PZ267_1.0': 8.83783531,\n",
       " 'P025_3.0': 8.82002258,\n",
       " 'PC095_5': 8.81733131,\n",
       " 'PC095_1': 8.80056381,\n",
       " 'PY098': 8.740114066666665,\n",
       " 'PA102': 8.71482277,\n",
       " 'PC229': 8.579467300000001,\n",
       " 'PJ677_4': 8.57328033,\n",
       " 'PD115_5.0': 8.55257225,\n",
       " 'PD101_2.0': 8.542391295,\n",
       " 'PX083': 8.53853035,\n",
       " 'PN090_2': 8.46205521,\n",
       " 'PZ270_6.0': 8.45590496,\n",
       " 'PE140_3.0': 8.40847588,\n",
       " 'PC085_1.0': 8.39334106,\n",
       " 'PY007': 8.2819166175,\n",
       " 'PQ488_1A': 8.24978065,\n",
       " 'PG041_7.0': 8.19158363,\n",
       " 'PE120_2.0': 8.07954597,\n",
       " 'PC085_3.0': 8.0664444,\n",
       " 'PD182M2': 8.01612711,\n",
       " 'PQ446_1.0': 7.96914196,\n",
       " 'PA071_5.0': 7.87755632,\n",
       " 'PY005': 7.738827696666665,\n",
       " 'P017M1': 7.71814751,\n",
       " 'PZ051_2.0': 7.71721554,\n",
       " 'PG058_1.0': 7.699802634999999,\n",
       " 'P037_3.0': 7.69901848,\n",
       " 'PD104_21': 7.532696725,\n",
       " 'PC104_1.0': 7.52515602,\n",
       " 'PX004_R': 7.494482039999999,\n",
       " 'PLBELIG_1': 7.48982096,\n",
       " 'PG010_6.0': 7.4269309,\n",
       " 'PB082_2.0': 7.39254379,\n",
       " 'PC148_1.0': 7.35026836,\n",
       " 'PZ044_1.0': 7.33519173,\n",
       " 'PD183M1': 7.265858175,\n",
       " 'PC005_1.0': 7.23386049,\n",
       " 'PJ005M1_1.0': 7.1832571,\n",
       " 'PD143': 7.173156420000001,\n",
       " 'PZ267_3.0': 7.15363693,\n",
       " 'PX084': 7.115665753333334,\n",
       " 'P024_2.0': 7.11218691,\n",
       " 'PE118_1.0': 7.032979965,\n",
       " 'PC087_1.0': 7.03133774,\n",
       " 'PT011_5.0': 6.88044643,\n",
       " 'PC288_7.0': 6.76806068,\n",
       " 'PY114': 6.690986252,\n",
       " 'PC103_4.0': 6.66507339,\n",
       " 'PA100': 6.624000546666667,\n",
       " 'P022A_1.0': 6.61470652,\n",
       " 'PX007_R_4': 6.59920502,\n",
       " 'PC289_1.0': 6.424496175,\n",
       " 'PZ087_1.0': 6.3561039,\n",
       " 'PP047': 6.32592773,\n",
       " 'PC010_5.0': 6.30925369,\n",
       " 'PN007_1.0': 6.293933395,\n",
       " 'PP185_3.0': 6.27825737,\n",
       " 'PB000_2.0': 6.04711676,\n",
       " 'PN235_1.0': 6.03061438,\n",
       " 'PE105_5.0': 5.79008293,\n",
       " 'PF_CPL_0': 5.74111223,\n",
       " 'PB000_4.0': 5.68948555,\n",
       " 'P024_3.0': 5.58557606,\n",
       " 'PJ3707_1.0': 5.45128441,\n",
       " 'PC143_1.0': 5.23671675,\n",
       " 'PN209': 5.21045303,\n",
       " 'PD117_5.0': 5.03178978}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = clf_xgb.get_booster().get_score(importance_type=\"gain\")\n",
    "dict(sorted(x.items(), key=lambda item: item[1], reverse=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here are the top 15 important predictors:\n",
    "\n",
    "PD240_1.0: number series 2, 4, 6 - correct\n",
    "\n",
    "PQR011_5.0: who worked for pay last calendar year? (spouse, self, both?)\n",
    "\n",
    "PG040_5.0: have difficulty using a map - no\n",
    "\n",
    "PP005: what are the chances that you and your partner will leave an inheritance totaling $10,000 or more?\n",
    "\n",
    "PD186:  NUMBER FORGOTTEN - DELAYED\n",
    "\n",
    "\n",
    "PNSSCORE: The standard error of number series score\n",
    "\n",
    "PN164_5.0: in the last two year, have you seen a dentist for dental care, including dentures? - no\n",
    "\n",
    "PQ162_5.0: have money in IRA account?\n",
    "\n",
    "PQ344_1.0: have any checking or savings accounts or money market funds?\n",
    "\n",
    "PD184: NUMBER GOOD - DELAYED\n",
    "\n",
    "\n",
    "PP155: Number of percent range questions asked\n",
    "\n",
    "PN164_1.0: in the last two year, have you seen a dentist for dental care, including dentures? - yes\n",
    "\n",
    "PP097_3.0: How closely do you follow the stock market: very closely, somewhat, or not at all?\n",
    "\n",
    "PN098_2: R'S HEALTH INSURANCE PAYS PART OF PRESCRIPTION AND/OR DENTAL (not true)\n",
    "\n",
    "PG198_5.0: Have you spent any time in the past 12 months helping friends, neighbors, or relatives who did not live with you and did not pay you for the help?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In conclusion we...\n",
    "\n",
    "- **[Loaded the Data From a File](#download-the-data)**\n",
    "\n",
    "- **[Formatted the Data for XGBoost using One-Hot Encoding](#one-hot-encoding)**\n",
    "\n",
    "- **[Built an XGBoost Model for Classification](#build-tree)**\n",
    "\n",
    "- **[Optimize the XGBoost Parameters with Cross Validation and GridSearch()](#prune-tree)**\n",
    "\n",
    "- **[Built, Drew, Interpreted and Evaluated the Optimized XGBoost Model](#draw-tree)**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
